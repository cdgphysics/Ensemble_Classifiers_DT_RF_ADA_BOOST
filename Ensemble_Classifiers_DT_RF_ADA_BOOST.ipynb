{"cells":[{"cell_type":"markdown","metadata":{"id":"pWyrcftS3Wvj"},"source":["###Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aiokjbElepLh"},"outputs":[],"source":["# import packages\n","import copy\n","from math import log2, sqrt\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, RocCurveDisplay, precision_recall_curve, PrecisionRecallDisplay, average_precision_score, auc"]},{"cell_type":"markdown","metadata":{"id":"AV2_Rc9S3Zu7"},"source":["###Import data file and look for missing records"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kxbwYTDoe2fk"},"outputs":[],"source":["# load dataset\n","file_path = \"spam.data\"\n","df = pd.read_csv(file_path, delimiter=\" \")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gpEOFEjkfklh"},"outputs":[],"source":["# determine if data is missing features' values\n","missing_records = np.where(pd.isnull(df))\n","for records in missing_records:\n","  if records.size > 0:\n","    print(\"There is at least one missing features' values\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":130,"status":"ok","timestamp":1651240911194,"user":{"displayName":"Christopher Griffith","userId":"01499139913509777609"},"user_tz":240},"id":"T_AbhZAZfH3y","outputId":"b62f2f20-296b-4212-870a-dc9de6108bb2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["make            4.54\n","address        14.28\n","all              5.1\n","3d             42.81\n","our             10.0\n","over            5.88\n","remove          7.27\n","internet       11.11\n","order           5.26\n","mail           18.18\n","receive         2.61\n","will            9.67\n","people          5.55\n","report          10.0\n","addresses       4.41\n","free            20.0\n","business        7.14\n","email           9.09\n","you            18.75\n","credit         18.18\n","your           11.11\n","font            17.1\n","000             5.45\n","money           12.5\n","hp             20.83\n","hpl            16.66\n","george         33.33\n","650             9.09\n","lab            14.28\n","labs            5.88\n","telnet          12.5\n","857             4.76\n","data           18.18\n","415             4.76\n","85              20.0\n","technology      7.69\n","1999            6.89\n","parts           8.33\n","pm             11.11\n","direct          4.76\n","cs              7.14\n","meeting        14.28\n","original        3.57\n","project         20.0\n","re             21.42\n","edu            22.05\n","table           2.17\n","conference      10.0\n","semicol        4.385\n","paren          9.752\n","bracket        4.081\n","bang          32.478\n","dollar         6.003\n","pound         19.829\n","cap_avg       1102.5\n","cap_long        9989\n","cap_total      15841\n","Class           spam\n","dtype: object"]},"metadata":{},"execution_count":9}],"source":["df.max()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1651240911194,"user":{"displayName":"Christopher Griffith","userId":"01499139913509777609"},"user_tz":240},"id":"Tp3g57nsf-Qw","outputId":"99493de2-4f7e-4afc-dea1-510ecb871feb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["make          0.0\n","address       0.0\n","all           0.0\n","3d            0.0\n","our           0.0\n","over          0.0\n","remove        0.0\n","internet      0.0\n","order         0.0\n","mail          0.0\n","receive       0.0\n","will          0.0\n","people        0.0\n","report        0.0\n","addresses     0.0\n","free          0.0\n","business      0.0\n","email         0.0\n","you           0.0\n","credit        0.0\n","your          0.0\n","font          0.0\n","000           0.0\n","money         0.0\n","hp            0.0\n","hpl           0.0\n","george        0.0\n","650           0.0\n","lab           0.0\n","labs          0.0\n","telnet        0.0\n","857           0.0\n","data          0.0\n","415           0.0\n","85            0.0\n","technology    0.0\n","1999          0.0\n","parts         0.0\n","pm            0.0\n","direct        0.0\n","cs            0.0\n","meeting       0.0\n","original      0.0\n","project       0.0\n","re            0.0\n","edu           0.0\n","table         0.0\n","conference    0.0\n","semicol       0.0\n","paren         0.0\n","bracket       0.0\n","bang          0.0\n","dollar        0.0\n","pound         0.0\n","cap_avg       1.0\n","cap_long        1\n","cap_total       1\n","Class         ham\n","dtype: object"]},"metadata":{},"execution_count":10}],"source":["df.min()"]},{"cell_type":"markdown","metadata":{"id":"4yF8My4FPIeu"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"W7TrkIbA3j7j"},"source":["###Data - Raw, Normalized, Standardized"]},{"cell_type":"code","source":["# raw data\n","df_raw = df.drop(labels = 'Class', axis = 1 )\n","\n","# normalization of features\n","norm_scaler = MinMaxScaler()\n","normalized = norm_scaler.fit_transform(df.drop(labels = 'Class', axis = 1 ))\n","df_normalized = pd.DataFrame(normalized, columns = df.drop(labels = 'Class', axis = 1 ).columns)\n","\n","# standardization of features\n","standard_scaler = StandardScaler()\n","standardized = standard_scaler.fit_transform(df.drop(labels = 'Class', axis = 1 ))\n","df_standardized = pd.DataFrame(standardized, columns = df.drop(labels = 'Class', axis = 1 ).columns)\n"],"metadata":{"id":"wTGSyt_dvsLy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def data_selection(selection):\n","\n","    if selection is \"df_raw\":\n","      return df_raw\n","\n","    if selection is \"df_normalized\":\n","      return df_normalized\n","\n","    if selection is \"df_standardized\":\n","      return df_standardized"],"metadata":{"id":"UORjfGI23zsF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_nkc5RG_32VS"},"source":["###Parameters for each classifier"]},{"cell_type":"markdown","metadata":{"id":"iI2KKvAw5HGI"},"source":["####(1) Decision Tree ([Library](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I-JT28RS5VW3"},"outputs":[],"source":["legend_label_DTC = ['log(N)', 'sqrt(N)', 'N/2', 'N'] #number of features to consider at each split (plot legend)\n","N_DTC = len(df_raw.columns) # total features in dataset\n","considered_features_DTC = ['log2', 'auto', round(N_DTC/2), None] #number of features to consider at each split\n","features_per_config_DTC = [round(log2(N_DTC)), round(sqrt(N_DTC)), round(float(N_DTC/2)), N_DTC] # num of features per configuration\n","\n","predictions_DTC = [] # stores predictions \n","accuracies_by_num_features_DTC = [] # stores accuracies \n","cms_DTC = [] # stores confusion matrices \n","probs_DTC = [] # stores score probabilities of the test data "]},{"cell_type":"markdown","metadata":{"id":"piaUbkYR5N-v"},"source":["####(2) Random Forest ([Library](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=random%20forest#sklearn.ensemble.RandomForestClassifier))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mdhOgxDfnOFH"},"outputs":[],"source":["legend_label_RFC = ['log(N)', 'sqrt(N)', 'N/2', 'N'] #number of features to consider at each split (plot legend)\n","N_RFC = len(df_raw.columns) # total features in dataset\n","considered_features_RFC = ['log2', 'auto', round(N_RFC/2), None] #number of features to consider at each split\n","features_per_config_RFC = [round(log2(N_RFC)), round(sqrt(N_RFC)), round(float(N_RFC/2)), N_RFC ] # num of features per configuration\n","n_of_base_learners_RFC = [1, 10, 50, 100, 500, 1000, 5000] #number of base learners\n","\n","predictions_RFC = [] # stores predictions for each RandomForestClassifier model\n","accuracies_by_num_features_RFC = [] # stores accuracies for each RandomForestClassifier model\n","cms_RFC = [] # stores confusion matrices for each RandomForestClassifier model\n","probs_RFC = [] # stores score probabilities of the test data for each RandomForestClassifier model"]},{"cell_type":"markdown","metadata":{"id":"uQ9AEY7m5RR_"},"source":["####(3) & (4) Boosting (Ada) Ensemble with logistic regression classifier as the base learner, AdaBoost Ensemble with Decision Tree as the base learner ([Library](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html?highlight=adaboost#sklearn.ensemble.AdaBoostClassifier))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v0UepB1247tI"},"outputs":[],"source":["legend_label_Boost = ['log(N)', 'sqrt(N)', 'N/2', 'N'] #number of features to consider at each split (plot legend)\n","N_Boost = len(df_raw.columns) # total features in dataset\n","considered_features_Boost = ['log2', 'auto', round(N_Boost/2), None] #number of features to consider at each split\n","features_per_config_Boost = [round(log2(N_Boost)), round(sqrt(N_Boost)), round(float(N_Boost/2)), N_Boost ] # num of features per configuration\n","n_of_base_learners_Boost = [1, 10, 50, 100, 500, 1000, 5000] #number of base learners\n","\n","predictions_Boost = [] # stores predictions\n","accuracies_by_num_base_learners_Boost = [] # stores accuracies\n","cms_Boost = [] # stores confusion matrices\n","probs_Boost = [] # stores score probabilities of the test data"]},{"cell_type":"markdown","metadata":{"id":"zu0tJOuo4BgS"},"source":["### Functions for each classifier"]},{"cell_type":"markdown","metadata":{"id":"qoAq_pEUH1oT"},"source":["####(1) Decision Trees"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E2hnBgajQAz9"},"outputs":[],"source":["def initialize_DTC():\n","  predictions_DTC.clear()\n","  accuracies_by_num_features_DTC.clear()\n","  cms_DTC.clear()\n","  probs_DTC.clear()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AlKED8-YTNKf"},"outputs":[],"source":["def DTC_predictions():  \n","\n","  print(\"------BEGIN: Decision Tree Classifiers------\")\n","  # loop through each tunable model\n","  for index, feature_config in enumerate(tqdm(considered_features_DTC, ascii=True, unit='Feature Config')):\n","\n","    print('')\n","    print(\"---------------------------\")\n","    print('')\n","    print(\"Feature Config:\", legend_label_DTC[index], \"= {} Features\".format(features_per_config_DTC[index]))\n","\n","    # classifier\n","    dtc = DecisionTreeClassifier(criterion = \"entropy\", random_state = rng_seed,  max_features=feature_config)\n","\n","    # train rfc model using training split\n","    dtc.fit(X_train,Y_train)\n","\n","    # apply model to test split\n","    Y_pred = dtc.predict(X_test)\n","    Y_score = dtc.predict_proba(X_test)\n","    \n","    # store predictions, accuracy and probability scores\n","    predictions_DTC.append(Y_pred)\n","    accuracies_by_num_features_DTC.append(accuracy_score(Y_test, Y_pred))\n","    probs_DTC.append(Y_score)\n","\n","    # store confusion matrix\n","    cm = confusion_matrix(Y_test, Y_pred, labels=class_labels)\n","    cms_DTC.append(cm)\n","\n","    # display stats\n","    print(\"\\nAccuracy:\", round(accuracies_by_num_features_DTC[index]*100,4), \"%\\n\")\n"," \n","    TN, FP, FN, TP = cms_DTC[index].ravel()\n","\n","    print('(TN, FP, FN, TP) =', (TN, FP, FN, TP),'\\n')\n","\n","    cm_display = ConfusionMatrixDisplay(confusion_matrix=cms_DTC[index], display_labels=class_labels)\n","    cm_display.plot()\n","    plt.show()\n","\n","    # True Positive Rate TPR = TP/(TP+FN)\n","    TPR = TP/(TP+FN)\n","    print(\"\\nTrue Positive Rate: TPR = TP/(TP+FN) =\",round(TPR*100, 4), \"%\")\n","\n","    # True Negative Rate TNR = TN/(TN+FP)\n","    TNR = TN/(FP+TN)\n","    print(\"\\nTrue Negative Rate: TNR = TN/(TN+FP) =\",round(TNR*100, 4), \"%\")\n","\n","    # False Positive Rate FPR = FP/(FP+TN)\n","    FPR = FP/(FP+TN)\n","    print(\"\\nFalse Positive Rate: FPR = FP/(FP+TN) =\",round(FPR*100, 4), \"%\")\n","\n","    # False Negative Rate FNR = FN/(FN+TP)\n","    FNR = FN/(FN+TP)\n","    print(\"\\nFalse Negative Rate: FNR = FN/(FN+TP) =\",round(FNR*100, 4), \"%\\n\")\n","\n","    # Precision\n","    PRECISION = TP/(TP+FP)\n","    print(\"Precision Rate =\",round(PRECISION*100, 4), \"%\")\n","\n","    # Recall\n","    RECALL = TP/(TP+FN)\n","    print(\"Recall Rate =\",round(RECALL*100, 4), \"%\\n\")\n","\n","    # get false and true positive rates\n","    fpr, tpr, thresholds_roc = roc_curve(Y_test, probs_DTC[index][:,1], pos_label='spam')\n","    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n","\n","    # get area under the curve\n","    roc_auc = auc(fpr, tpr)\n","\n","    # get prec and recall rates\n","    prec, recall, thresholds_prc = precision_recall_curve(Y_test, probs_DTC[index][:,1], pos_label='spam')\n","    pr_display = PrecisionRecallDisplay(precision=prec, recall=recall)\n","\n","    # get area under the curve\n","    pr_auc = auc(recall, prec)\n","\n","    fig, (ax1, ax2) = plt.subplots(1, 2)\n","    fig.set_size_inches(8, 5)\n","\n","    ax1.plot(fpr, tpr, lw=1)\n","    ax1.plot(FPR, TPR, marker=\"o\", ms = 2, color = 'red')\n","    ax1.set_title('ROC\\nAUC = {}'.format(round(roc_auc,4)))\n","    ax1.set(xlabel = 'False Positive Rate', ylabel = 'True Positive Rate')\n","    ax1.set_xlim([-.1, 1.1])\n","\n","    ax2.plot(recall, prec, lw=1)\n","    ax2.plot(RECALL, PRECISION, marker=\"o\", ms = 2, color = 'red')\n","    ax2.set_title('PR\\nAUC = {}'.format(round(pr_auc,4)))\n","    ax2.set(xlabel = 'Recall', ylabel = 'Precision')\n","    ax2.set_xlim([-.1, 1.1])\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","  print(\"\\n-----END-----\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pwoRf4xFZwQk"},"outputs":[],"source":["# Plot graphs (RFC)\n","def plot_all_graphs_DTC():\n","\n","  # plot Accuracies of DTCs vs Num of Features \n","\n","  adj_range = range(len(features_per_config_DTC))\n","\n","  plt.plot(adj_range, accuracies_by_num_features_DTC, marker=\"o\")\n","\n","  print('\\n-------DTCs SUMMARY-------\\n')\n","  #plt.legend(legend_label_DTC, loc=\"best\")\n","  plt.title(\"Accuracies of DTCs vs Number of Features\")\n","  plt.ylabel(f\"Accuracies\")\n","  plt.xlabel(\"Number of Features\")\n","  plt.xticks(adj_range, features_per_config_DTC)\n","\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TWWIt7Ofa8F5"},"outputs":[],"source":["def best_accuracy_DTC():\n","  best_estimator = ['', 0, 0]\n","  max_index = 0\n","  \n","  max_accuracy = max(accuracies_by_num_features_DTC)\n","  max_index = accuracies_by_num_features_DTC.index(max_accuracy)\n","\n","  print('\\n-----BEST PERFORMANCE-----\\n')\n","  print(\"Feature Config:\", legend_label_DTC[max_index], \"= {} Features with accuracy:\".format(features_per_config_DTC[max_index]), round(max_accuracy*100, 4), \"%\\n\")\n","\n","  cm = cms_DTC[max_index]\n","\n","  TN, FP, FN, TP = cm.ravel()\n","\n","  print('(TN, FP, FN, TP) =', (TN, FP, FN, TP),'\\n')\n","\n","  cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n","  cm_display.plot()\n","  plt.show()\n","\n","  # True Positive Rate TPR = TP/(TP+FN)\n","  TPR = TP/(TP+FN)\n","  print(\"\\nTrue Positive Rate: TPR = TP/(TP+FN) =\",round(TPR*100, 4), \"%\")\n","\n","  # True Negative Rate TNR = TN/(TN+FP)\n","  TNR = TN/(FP+TN)\n","  print(\"\\nTrue Negative Rate: TNR = TN/(TN+FP) =\",round(TNR*100, 4), \"%\")\n","\n","  # False Positive Rate FPR = FP/(FP+TN)\n","  FPR = FP/(FP+TN)\n","  print(\"\\nFalse Positive Rate: FPR = FP/(FP+TN) =\",round(FPR*100, 4), \"%\")\n","\n","  # False Negative Rate FNR = FN/(FN+TP)\n","  FNR = FN/(FN+TP)\n","  print(\"\\nFalse Negative Rate: FNR = FN/(FN+TP) =\",round(FNR*100, 4), \"%\\n\")\n","\n","  # Precision\n","  PRECISION = TP/(TP+FP)\n","  print(\"Precision Rate =\",round(PRECISION*100, 4), \"%\")\n","\n","  # Recall\n","  RECALL = TP/(TP+FN)\n","  print(\"Recall Rate =\",round(RECALL*100, 4), \"%\\n\")\n","\n","  # get false and true positive rates\n","  fpr, tpr, thresholds_roc = roc_curve(Y_test, probs_DTC[max_index][:,1], pos_label='spam')\n","  roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n","\n","  # get area under the curve\n","  roc_auc = auc(fpr, tpr)\n","\n","  # get prec and recall rates\n","  prec, recall, thresholds_prc = precision_recall_curve(Y_test, probs_DTC[max_index][:,1], pos_label='spam')\n","  pr_display = PrecisionRecallDisplay(precision=prec, recall=recall)\n","\n","  # get area under the curve\n","  pr_auc = auc(recall, prec)\n","\n","  fig, (ax1, ax2) = plt.subplots(1, 2)\n","  fig.set_size_inches(8, 5)\n","\n","  ax1.plot(fpr, tpr, lw=1)\n","  ax1.plot(FPR, TPR, marker=\"o\", ms = 2, color = 'red')\n","  ax1.set_title('ROC\\nAUC = {}'.format(round(roc_auc,4)))\n","  ax1.set(xlabel = 'False Positive Rate', ylabel = 'True Positive Rate')\n","  ax1.set_xlim([-.1, 1.1])\n","\n","  ax2.plot(recall, prec, lw=1)\n","  ax2.plot(RECALL, PRECISION, marker=\"o\", ms = 2, color = 'red')\n","  ax2.set_title('PR\\nAUC = {}'.format(round(pr_auc,4)))\n","  ax2.set(xlabel = 'Recall', ylabel = 'Precision')\n","  ax2.set_xlim([-.1, 1.1])\n","\n","  plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q8frscF_TIP_"},"outputs":[],"source":["def DTC_Evaluation():\n","  initialize_DTC()\n","  DTC_predictions()\n","  plot_all_graphs_DTC()\n","  best_accuracy_DTC()"]},{"cell_type":"markdown","metadata":{"id":"cM9sNjceIKkS"},"source":["####(2) Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wWRRhrdjJeHp"},"outputs":[],"source":["def initialize_RFC():\n","  predictions_RFC.clear()\n","  accuracies_by_num_features_RFC.clear()\n","  cms_RFC.clear()\n","  probs_RFC.clear()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHb5-abM4Q8J"},"outputs":[],"source":["def RFC_predictions():  \n","\n","  print(\"------BEGIN: Random Forest Classifiers------\")\n","  # loop through each tunable model\n","  for index, feature_config in enumerate(tqdm(considered_features_RFC, ascii=True, unit='Feature Config')):\n","\n","    print('')\n","    print(\"---------------------------\")\n","    print('')\n","    print(\"Feature Config:\", legend_label_RFC[index], \"= {} Features\".format(features_per_config_RFC[index]))\n","    \n","    predictions = []\n","    accuracies = []\n","    cms = []\n","    probs = []\n","\n","    for base_learner in tqdm(n_of_base_learners_RFC, ascii=True, unit='Base Learners Config'):\n","\n","      # classifier\n","      rfc = RandomForestClassifier(n_estimators=base_learner, criterion = \"entropy\", bootstrap = True, random_state = rng_seed, max_features=feature_config)\n","\n","      # train rfc model using training split\n","      rfc.fit(X_train,Y_train)\n","\n","      # apply model to test split\n","      Y_pred = rfc.predict(X_test)\n","      Y_score = rfc.predict_proba(X_test)\n","     \n","      # store predictions, accuracy abd probability scores\n","      predictions.append(Y_pred)\n","      accuracies.append(accuracy_score(Y_test, Y_pred))\n","      probs.append(Y_score)\n","\n","      # store confusion matrix\n","      cm = confusion_matrix(Y_test, Y_pred, labels=class_labels)\n","      cms.append(cm)\n","    \n","    predictions_RFC.append(predictions)\n","    accuracies_by_num_features_RFC.append(accuracies)\n","    cms_RFC.append(cms)\n","    probs_RFC.append(probs)\n","\n","    # display stats of best classifier by Base Learner Config\n","    max_accuracy = max(accuracies)\n","    max_index = accuracies.index(max_accuracy)\n","    print(\"\\nMax Accuracy ({} base learners):\".format(n_of_base_learners_RFC[max_index]), round(max_accuracy*100,4), \"%\\n\")\n"," \n","    TN, FP, FN, TP = cms[max_index].ravel()\n","\n","    print('(TN, FP, FN, TP) =', (TN, FP, FN, TP),'\\n')\n","\n","    cm_display = ConfusionMatrixDisplay(confusion_matrix=cms[max_index], display_labels=class_labels)\n","    cm_display.plot()\n","    plt.show()\n","\n","    # True Positive Rate TPR = TP/(TP+FN)\n","    TPR = TP/(TP+FN)\n","    print(\"\\nTrue Positive Rate: TPR = TP/(TP+FN) =\",round(TPR*100, 4), \"%\")\n","\n","    # True Negative Rate TNR = TN/(TN+FP)\n","    TNR = TN/(FP+TN)\n","    print(\"\\nTrue Negative Rate: TNR = TN/(TN+FP) =\",round(TNR*100, 4), \"%\")\n","\n","    # False Positive Rate FPR = FP/(FP+TN)\n","    FPR = FP/(FP+TN)\n","    print(\"\\nFalse Positive Rate: FPR = FP/(FP+TN) =\",round(FPR*100, 4), \"%\")\n","\n","    # False Negative Rate FNR = FN/(FN+TP)\n","    FNR = FN/(FN+TP)\n","    print(\"\\nFalse Negative Rate: FNR = FN/(FN+TP) =\",round(FNR*100, 4), \"%\\n\")\n","\n","    # Precision\n","    PRECISION = TP/(TP+FP)\n","    print(\"Precision Rate =\",round(PRECISION*100, 4), \"%\")\n","\n","    # Recall\n","    RECALL = TP/(TP+FN)\n","    print(\"Recall Rate =\",round(RECALL*100, 4), \"%\\n\")\n","\n","    # get false and true positive rates\n","    fpr, tpr, thresholds_roc = roc_curve(Y_test, probs[max_index][:,1], pos_label='spam')\n","    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n","\n","    # get area under the curve\n","    roc_auc = auc(fpr, tpr)\n","\n","    # get prec and recall rates\n","    prec, recall, thresholds_prc = precision_recall_curve(Y_test, probs[max_index][:,1], pos_label='spam')\n","    pr_display = PrecisionRecallDisplay(precision=prec, recall=recall)\n","\n","    # get area under the curve\n","    pr_auc = auc(recall, prec)\n","\n","    fig, (ax1, ax2) = plt.subplots(1, 2)\n","    fig.set_size_inches(8, 5)\n","\n","    ax1.plot(fpr, tpr, lw=1)\n","    ax1.plot(FPR, TPR, marker=\"o\", ms = 2, color = 'red')\n","    ax1.set_title('ROC\\nAUC = {}'.format(round(roc_auc,4)))\n","    ax1.set(xlabel = 'False Positive Rate', ylabel = 'True Positive Rate')\n","    ax1.set_xlim([-.1, 1.1])\n","\n","    ax2.plot(recall, prec, lw=1)\n","    ax2.plot(RECALL, PRECISION, marker=\"o\", ms = 2, color = 'red')\n","    ax2.set_title('PR\\nAUC = {}'.format(round(pr_auc,4)))\n","    ax2.set(xlabel = 'Recall', ylabel = 'Precision')\n","    ax2.set_xlim([-.1, 1.1])\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","  print(\"\\n-----END-----\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P3LgM6rcrbBf"},"outputs":[],"source":["# Plot graphs (RFC)\n","def plot_all_graphs_RFC():\n","\n","  # plot Accuracies of RFCs vs Number of Base Learners \n","  line_style = ['-', '--', '-.', ':']\n","\n","  adj_range = range(len(n_of_base_learners_RFC))\n","\n","  for index, accuracies in enumerate(accuracies_by_num_features_RFC):\n","    plt.plot(adj_range, accuracies, line_style[index], marker=\"o\")\n","\n","  print('\\n-------RFCs SUMMARY-------\\n')\n","  plt.legend(legend_label_RFC, loc=\"best\")\n","  plt.title(\"Accuracies of RFCs vs Number of Base Learners\")\n","  plt.ylabel(f\"Accuracies\")\n","  plt.xlabel(\"Number of Base Learners\")\n","  plt.xticks(adj_range, n_of_base_learners_RFC)\n","\n","  plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xcRoRQZi4lWx"},"outputs":[],"source":["def best_accuracy_RFC():\n","  best_estimator = ['', 0, 0, 0, 0]\n","  max_index = 0\n","  for index, accuracies in enumerate(accuracies_by_num_features_RFC):\n","      max_accuracy = max(accuracies)\n","      max_index = accuracies.index(max_accuracy)\n","\n","      if best_estimator[4] < max_accuracy:\n","        best_estimator[0] = legend_label_RFC[index]\n","        best_estimator[1] = index\n","        best_estimator[2] = n_of_base_learners_RFC[max_index]\n","        best_estimator[3] = max_index\n","        best_estimator[4] = max_accuracy\n","\n","  print('\\n-----BEST PERFORMANCE-----\\n')\n","  print(\"Feature Config:\", best_estimator[0], \" = {} Features with accuracy ({} base learners):\".format(features_per_config_RFC[best_estimator[1]],best_estimator[2]), round(best_estimator[4]*100, 4), \"%\\n\")\n","\n","  cm = cms_RFC[best_estimator[1]][best_estimator[3]]\n","\n","  TN, FP, FN, TP = cm.ravel()\n","\n","  print('(TN, FP, FN, TP) =', (TN, FP, FN, TP),'\\n')\n","\n","  cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n","  cm_display.plot()\n","  plt.show()\n","\n","  # True Positive Rate TPR = TP/(TP+FN)\n","  TPR = TP/(TP+FN)\n","  print(\"\\nTrue Positive Rate: TPR = TP/(TP+FN) =\",round(TPR*100, 4), \"%\")\n","\n","  # True Negative Rate TNR = TN/(TN+FP)\n","  TNR = TN/(FP+TN)\n","  print(\"\\nTrue Negative Rate: TNR = TN/(TN+FP) =\",round(TNR*100, 4), \"%\")\n","\n","  # False Positive Rate FPR = FP/(FP+TN)\n","  FPR = FP/(FP+TN)\n","  print(\"\\nFalse Positive Rate: FPR = FP/(FP+TN) =\",round(FPR*100, 4), \"%\")\n","\n","  # False Negative Rate FNR = FN/(FN+TP)\n","  FNR = FN/(FN+TP)\n","  print(\"\\nFalse Negative Rate: FNR = FN/(FN+TP) =\",round(FNR*100, 4), \"%\\n\")\n","\n","  # Precision\n","  PRECISION = TP/(TP+FP)\n","  print(\"Precision Rate =\",round(PRECISION*100, 4), \"%\")\n","\n","  # Recall\n","  RECALL = TP/(TP+FN)\n","  print(\"Recall Rate =\",round(RECALL*100, 4), \"%\\n\")\n","\n","  # get false and true positive rates\n","  fpr, tpr, thresholds_roc = roc_curve(Y_test, probs_RFC[best_estimator[1]][best_estimator[3]][:,1], pos_label='spam')\n","  roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n","\n","  # get area under the curve\n","  roc_auc = auc(fpr, tpr)\n","\n","  # get prec and recall rates\n","  prec, recall, thresholds_prc = precision_recall_curve(Y_test, probs_RFC[best_estimator[1]][best_estimator[3]][:,1], pos_label='spam')\n","  pr_display = PrecisionRecallDisplay(precision=prec, recall=recall)\n","\n","  # get area under the curve\n","  pr_auc = auc(recall, prec)\n","\n","  fig, (ax1, ax2) = plt.subplots(1, 2)\n","  fig.set_size_inches(8, 5)\n","\n","  ax1.plot(fpr, tpr, lw=1)\n","  ax1.plot(FPR, TPR, marker=\"o\", ms = 2, color = 'red')\n","  ax1.set_title('ROC\\nAUC = {}'.format(round(roc_auc,4)))\n","  ax1.set(xlabel = 'False Positive Rate', ylabel = 'True Positive Rate')\n","  ax1.set_xlim([-.1, 1.1])\n","\n","  ax2.plot(recall, prec, lw=1)\n","  ax2.plot(RECALL, PRECISION, marker=\"o\", ms = 2, color = 'red')\n","  ax2.set_title('PR\\nAUC = {}'.format(round(pr_auc,4)))\n","  ax2.set(xlabel = 'Recall', ylabel = 'Precision')\n","  ax2.set_xlim([-.1, 1.1])\n","\n","  plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TyfpP3i1LrRd"},"outputs":[],"source":["def RFC_Evaluation():\n","  initialize_RFC()\n","  RFC_predictions()\n","  plot_all_graphs_RFC()\n","  best_accuracy_RFC()"]},{"cell_type":"markdown","metadata":{"id":"69LMeEEwISWK"},"source":["####(3) & (4) Boosting (Ada) Ensemble with logistic regression classifier as the base learner, AdaBoost Ensemble with Decision Tree as the base learner"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBh59BAumDPt"},"outputs":[],"source":["def initialize_Boost():\n","  predictions_Boost.clear()\n","  accuracies_by_num_base_learners_Boost.clear()\n","  cms_Boost.clear()\n","  probs_Boost.clear()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"moFYjbDhoxxo"},"outputs":[],"source":["def Boost_LR_predictions():  \n","\n","  print(\"------BEGIN: Boosting Ensemble with Logistic Regression------\")\n","  # loop through each tunable model\n","  lr_est = LogisticRegression (max_iter = 10000, random_state=rng_seed)  #logistic regression classifier as the base learner\n","\n","  for index, base_learner in enumerate(tqdm(n_of_base_learners_Boost, ascii=True, unit='Base Learners Config')):\n","\n","    print('')\n","    print(\"---------------------------\")\n","    print('')\n","    print(\"Base Learner Config:\", base_learner)\n","\n","    # classifier\n","    bs_lr = AdaBoostClassifier(n_estimators = base_learner, base_estimator = lr_est)\n","\n","    # train model using training split\n","    bs_lr.fit(X_train,Y_train)\n","\n","    # apply model to test split\n","    Y_pred = bs_lr.predict(X_test)\n","    Y_score = bs_lr.predict_proba(X_test)\n","    \n","    # store predictions, accuracy abd probability scores\n","    predictions_Boost.append(Y_pred)\n","    accuracies_by_num_base_learners_Boost.append(accuracy_score(Y_test, Y_pred))\n","    probs_Boost.append(Y_score)\n","\n","    # store confusion matrix\n","    cm = confusion_matrix(Y_test, Y_pred, labels=class_labels)\n","    cms_Boost.append(cm)\n","\n","    # display stats\n","    print(\"\\nAccuracy:\", round(accuracies_by_num_base_learners_Boost[index]*100,4), \"%\\n\")\n"," \n","    TN, FP, FN, TP = cms_Boost[index].ravel()\n","\n","    print('(TN, FP, FN, TP) =', (TN, FP, FN, TP),'\\n')\n","\n","    cm_display = ConfusionMatrixDisplay(confusion_matrix=cms_Boost[index], display_labels=class_labels)\n","    cm_display.plot()\n","    plt.show()\n","\n","    # True Positive Rate TPR = TP/(TP+FN)\n","    TPR = TP/(TP+FN)\n","    print(\"\\nTrue Positive Rate: TPR = TP/(TP+FN) =\",round(TPR*100, 4), \"%\")\n","\n","    # True Negative Rate TNR = TN/(TN+FP)\n","    TNR = TN/(FP+TN)\n","    print(\"\\nTrue Negative Rate: TNR = TN/(TN+FP) =\",round(TNR*100, 4), \"%\")\n","\n","    # False Positive Rate FPR = FP/(FP+TN)\n","    FPR = FP/(FP+TN)\n","    print(\"\\nFalse Positive Rate: FPR = FP/(FP+TN) =\",round(FPR*100, 4), \"%\")\n","\n","    # False Negative Rate FNR = FN/(FN+TP)\n","    FNR = FN/(FN+TP)\n","    print(\"\\nFalse Negative Rate: FNR = FN/(FN+TP) =\",round(FNR*100, 4), \"%\\n\")\n","\n","    # Precision\n","    PRECISION = TP/(TP+FP)\n","    print(\"Precision Rate =\",round(PRECISION*100, 4), \"%\")\n","\n","    # Recall\n","    RECALL = TP/(TP+FN)\n","    print(\"Recall Rate =\",round(RECALL*100, 4), \"%\\n\")\n","\n","    # get false and true positive rates\n","    fpr, tpr, thresholds_roc = roc_curve(Y_test, probs_Boost[index][:,1], pos_label='spam')\n","    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n","\n","    # get area under the curve\n","    roc_auc = auc(fpr, tpr)\n","\n","    # get prec and recall rates\n","    prec, recall, thresholds_prc = precision_recall_curve(Y_test, probs_Boost[index][:,1], pos_label='spam')\n","    pr_display = PrecisionRecallDisplay(precision=prec, recall=recall)\n","\n","    # get area under the curve\n","    pr_auc = auc(recall, prec)\n","\n","    fig, (ax1, ax2) = plt.subplots(1, 2)\n","    fig.set_size_inches(8, 5)\n","\n","    ax1.plot(fpr, tpr, lw=1)\n","    ax1.plot(FPR, TPR, marker=\"o\", ms = 2, color = 'red')\n","    ax1.set_title('ROC\\nAUC = {}'.format(round(roc_auc,4)))\n","    ax1.set(xlabel = 'False Positive Rate', ylabel = 'True Positive Rate')\n","    ax1.set_xlim([-.1, 1.1])\n","\n","    ax2.plot(recall, prec, lw=1)\n","    ax2.plot(RECALL, PRECISION, marker=\"o\", ms = 2, color = 'red')\n","    ax2.set_title('PR\\nAUC = {}'.format(round(pr_auc,4)))\n","    ax2.set(xlabel = 'Recall', ylabel = 'Precision')\n","    ax2.set_xlim([-.1, 1.1])\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","  print(\"\\n-----END-----\")\n","\n","\n","def Boost_DTC_predictions():  \n","\n","  print(\"------BEGIN: AdaBoost Ensemble with Decision Tree------\")\n","\n","  # loop through each tunable model\n","  for index, feature_config in enumerate(tqdm(considered_features_Boost, ascii=True, unit='Feature Config')):\n","\n","    print('')\n","    print(\"---------------------------\")\n","    print('')\n","    print(\"Feature Config:\", legend_label_Boost[index], \"= {} Features\".format(features_per_config_Boost[index]))\n","    \n","    predictions = []\n","    accuracies = []\n","    cms = []\n","    probs = []\n","\n","    # decision tree classifier as the base learner for feature config\n","    dtc_est = DecisionTreeClassifier(criterion = \"entropy\", random_state = rng_seed, max_features=feature_config) \n","\n","    for base_learner in tqdm(n_of_base_learners_Boost, ascii=True, unit='Base Learners Config'):\n","\n","      # classifier\n","      bs_dtc = AdaBoostClassifier(n_estimators = base_learner, base_estimator = dtc_est)\n","\n","      # train model using training split\n","      bs_dtc.fit(X_train,Y_train)\n","\n","      # apply model to test split\n","      Y_pred = bs_dtc.predict(X_test)\n","      Y_score = bs_dtc.predict_proba(X_test)\n","      \n","      # store predictions, accuracy abd probability scores\n","      predictions.append(Y_pred)\n","      accuracies.append(accuracy_score(Y_test, Y_pred))\n","      probs.append(Y_score)\n","\n","      # store confusion matrix\n","      cm = confusion_matrix(Y_test, Y_pred, labels=class_labels)\n","      cms.append(cm)\n","    \n","    predictions_Boost.append(predictions)\n","    accuracies_by_num_base_learners_Boost.append(accuracies)\n","    cms_Boost.append(cms)\n","    probs_Boost.append(probs)\n","\n","    # display stats of best classifier by Base Learner Config\n","    max_accuracy = max(accuracies)\n","    max_index = accuracies.index(max_accuracy)\n","    print(\"\\nMax Accuracy ({} base learners):\".format(n_of_base_learners_Boost[max_index]), round(max_accuracy*100,4), \"%\\n\")\n","\n","    TN, FP, FN, TP = cms[max_index].ravel()\n","\n","    print('(TN, FP, FN, TP) =', (TN, FP, FN, TP),'\\n')\n","\n","    cm_display = ConfusionMatrixDisplay(confusion_matrix=cms[max_index], display_labels=class_labels)\n","    cm_display.plot()\n","    plt.show()\n","\n","    # True Positive Rate TPR = TP/(TP+FN)\n","    TPR = TP/(TP+FN)\n","    print(\"\\nTrue Positive Rate: TPR = TP/(TP+FN) =\",round(TPR*100, 4), \"%\")\n","\n","    # True Negative Rate TNR = TN/(TN+FP)\n","    TNR = TN/(FP+TN)\n","    print(\"\\nTrue Negative Rate: TNR = TN/(TN+FP) =\",round(TNR*100, 4), \"%\")\n","\n","    # False Positive Rate FPR = FP/(FP+TN)\n","    FPR = FP/(FP+TN)\n","    print(\"\\nFalse Positive Rate: FPR = FP/(FP+TN) =\",round(FPR*100, 4), \"%\")\n","\n","    # False Negative Rate FNR = FN/(FN+TP)\n","    FNR = FN/(FN+TP)\n","    print(\"\\nFalse Negative Rate: FNR = FN/(FN+TP) =\",round(FNR*100, 4), \"%\\n\")\n","\n","    # Precision\n","    PRECISION = TP/(TP+FP)\n","    print(\"Precision Rate =\",round(PRECISION*100, 4), \"%\")\n","\n","    # Recall\n","    RECALL = TP/(TP+FN)\n","    print(\"Recall Rate =\",round(RECALL*100, 4), \"%\\n\")\n","\n","    # get false and true positive rates\n","    fpr, tpr, thresholds_roc = roc_curve(Y_test, probs[max_index][:,1], pos_label='spam')\n","    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n","\n","    # get area under the curve\n","    roc_auc = auc(fpr, tpr)\n","\n","    # get prec and recall rates\n","    prec, recall, thresholds_prc = precision_recall_curve(Y_test, probs[max_index][:,1], pos_label='spam')\n","    pr_display = PrecisionRecallDisplay(precision=prec, recall=recall)\n","\n","    # get area under the curve\n","    pr_auc = auc(recall, prec)\n","\n","    fig, (ax1, ax2) = plt.subplots(1, 2)\n","    fig.set_size_inches(8, 5)\n","\n","    ax1.plot(fpr, tpr, lw=1)\n","    ax1.plot(FPR, TPR, marker=\"o\", ms = 2, color = 'red')\n","    ax1.set_title('ROC\\nAUC = {}'.format(round(roc_auc,4)))\n","    ax1.set(xlabel = 'False Positive Rate', ylabel = 'True Positive Rate')\n","    ax1.set_xlim([-.1, 1.1])\n","\n","    ax2.plot(recall, prec, lw=1)\n","    ax2.plot(RECALL, PRECISION, marker=\"o\", ms = 2, color = 'red')\n","    ax2.set_title('PR\\nAUC = {}'.format(round(pr_auc,4)))\n","    ax2.set(xlabel = 'Recall', ylabel = 'Precision')\n","    ax2.set_xlim([-.1, 1.1])\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","  print(\"\\n-----END-----\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxn2pQZooHzp"},"outputs":[],"source":["def plot_all_graphs_Boost_LR():\n","\n","  # plot Accuracies vs Num of Features \n","\n","  adj_range = range(len(n_of_base_learners_Boost))\n","\n","  plt.plot(adj_range, accuracies_by_num_base_learners_Boost, marker=\"o\")\n","\n","  print('\\n-------Boost LR SUMMARY-------\\n')\n","  plt.title(\"Accuracies of Boosting LR vs Number of Base Learners\")\n","  plt.ylabel(f\"Accuracies\")\n","  plt.xlabel(\"Number of Base Learners\")\n","  plt.xticks(adj_range, n_of_base_learners_Boost)\n","\n","  plt.show()\n","\n","\n","def plot_all_graphs_Boost_DTC():\n","\n","  # plot Accuracies  vs Number of Base Learners \n","  line_style = ['-', '--', '-.', ':']\n","\n","  adj_range = range(len(n_of_base_learners_Boost))\n","\n","  for index, accuracies in enumerate(accuracies_by_num_base_learners_Boost):\n","    plt.plot(adj_range, accuracies, line_style[index], marker=\"o\")\n","\n","  print('\\n-------BOOST DTC SUMMARY-------\\n')\n","  plt.legend(legend_label_Boost, loc=\"best\")\n","  plt.title(\"Accuracies of Boosting DTC vs Number of Base Learners\")\n","  plt.ylabel(f\"Accuracies\")\n","  plt.xlabel(\"Number of Base Learners\")\n","  plt.xticks(adj_range, n_of_base_learners_Boost)\n","\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MKMtCq6onc-y"},"outputs":[],"source":["def best_accuracy_Boost_DTC():\n","  best_estimator = ['', 0, 0, 0, 0]\n","  max_index = 0\n","  for index, accuracies in enumerate(accuracies_by_num_base_learners_Boost):\n","      max_accuracy = max(accuracies)\n","      max_index = accuracies.index(max_accuracy)\n","\n","      if best_estimator[4] < max_accuracy:\n","        best_estimator[0] = legend_label_Boost[index]\n","        best_estimator[1] = index\n","        best_estimator[2] = n_of_base_learners_Boost[max_index]\n","        best_estimator[3] = max_index\n","        best_estimator[4] = max_accuracy\n","\n","  print('\\n-----BEST PERFORMANCE-----\\n')\n","  print(\"Feature Config:\", best_estimator[0], \" = {} Features with accuracy ({} base learners):\".format(features_per_config_Boost[best_estimator[1]],best_estimator[2]), round(best_estimator[4]*100, 4), \"%\\n\")\n","\n","  cm = cms_Boost[best_estimator[1]][best_estimator[3]]\n","\n","  TN, FP, FN, TP = cm.ravel()\n","\n","  print('(TN, FP, FN, TP) =', (TN, FP, FN, TP),'\\n')\n","\n","  cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n","  cm_display.plot()\n","  plt.show()\n","\n","  # True Positive Rate TPR = TP/(TP+FN)\n","  TPR = TP/(TP+FN)\n","  print(\"\\nTrue Positive Rate: TPR = TP/(TP+FN) =\",round(TPR*100, 4), \"%\")\n","\n","  # True Negative Rate TNR = TN/(TN+FP)\n","  TNR = TN/(FP+TN)\n","  print(\"\\nTrue Negative Rate: TNR = TN/(TN+FP) =\",round(TNR*100, 4), \"%\")\n","\n","  # False Positive Rate FPR = FP/(FP+TN)\n","  FPR = FP/(FP+TN)\n","  print(\"\\nFalse Positive Rate: FPR = FP/(FP+TN) =\",round(FPR*100, 4), \"%\")\n","\n","  # False Negative Rate FNR = FN/(FN+TP)\n","  FNR = FN/(FN+TP)\n","  print(\"\\nFalse Negative Rate: FNR = FN/(FN+TP) =\",round(FNR*100, 4), \"%\\n\")\n","\n","  # Precision\n","  PRECISION = TP/(TP+FP)\n","  print(\"Precision Rate =\",round(PRECISION*100, 4), \"%\")\n","\n","  # Recall\n","  RECALL = TP/(TP+FN)\n","  print(\"Recall Rate =\",round(RECALL*100, 4), \"%\\n\")\n","\n","  # get false and true positive rates\n","  fpr, tpr, thresholds_roc = roc_curve(Y_test, probs_Boost[best_estimator[1]][best_estimator[3]][:,1], pos_label='spam')\n","  roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n","\n","  # get area under the curve\n","  roc_auc = auc(fpr, tpr)\n","\n","  # get prec and recall rates\n","  prec, recall, thresholds_prc = precision_recall_curve(Y_test, probs_Boost[best_estimator[1]][best_estimator[3]][:,1], pos_label='spam')\n","  pr_display = PrecisionRecallDisplay(precision=prec, recall=recall)\n","\n","  # get area under the curve\n","  pr_auc = auc(recall, prec)\n","\n","  fig, (ax1, ax2) = plt.subplots(1, 2)\n","  fig.set_size_inches(8, 5)\n","\n","  ax1.plot(fpr, tpr, lw=1)\n","  ax1.plot(FPR, TPR, marker=\"o\", ms = 2, color = 'red')\n","  ax1.set_title('ROC\\nAUC = {}'.format(round(roc_auc,4)))\n","  ax1.set(xlabel = 'False Positive Rate', ylabel = 'True Positive Rate')\n","  ax1.set_xlim([-.1, 1.1])\n","\n","  ax2.plot(recall, prec, lw=1)\n","  ax2.plot(RECALL, PRECISION, marker=\"o\", ms = 2, color = 'red')\n","  ax2.set_title('PR\\nAUC = {}'.format(round(pr_auc,4)))\n","  ax2.set(xlabel = 'Recall', ylabel = 'Precision')\n","  ax2.set_xlim([-.1, 1.1])\n","\n","  plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n","  plt.show()\n","\n","def best_accuracy_Boost_LR():\n","  best_estimator = ['', 0, 0]\n","  max_index = 0\n","  \n","  max_accuracy = max(accuracies_by_num_base_learners_Boost)\n","  max_index = accuracies_by_num_base_learners_Boost.index(max_accuracy)\n","\n","  print('\\n-----BEST PERFORMANCE-----\\n')\n","  print(\"Base Learner Config:\", n_of_base_learners_Boost[max_index], \"Base Learners with accuracy:\", round(max_accuracy*100, 4), \"%\\n\")\n","\n","  cm = cms_Boost[max_index]\n","\n","  TN, FP, FN, TP = cm.ravel()\n","\n","  print('(TN, FP, FN, TP) =', (TN, FP, FN, TP),'\\n')\n","\n","  cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n","  cm_display.plot()\n","  plt.show()\n","\n","  # True Positive Rate TPR = TP/(TP+FN)\n","  TPR = TP/(TP+FN)\n","  print(\"\\nTrue Positive Rate: TPR = TP/(TP+FN) =\",round(TPR*100, 4), \"%\")\n","\n","  # True Negative Rate TNR = TN/(TN+FP)\n","  TNR = TN/(FP+TN)\n","  print(\"\\nTrue Negative Rate: TNR = TN/(TN+FP) =\",round(TNR*100, 4), \"%\")\n","\n","  # False Positive Rate FPR = FP/(FP+TN)\n","  FPR = FP/(FP+TN)\n","  print(\"\\nFalse Positive Rate: FPR = FP/(FP+TN) =\",round(FPR*100, 4), \"%\\n\")\n","\n","  # False Negative Rate FNR = FN/(FN+TP)\n","  FNR = FN/(FN+TP)\n","  print(\"\\nFalse Negative Rate: FNR = FN/(FN+TP) =\",round(FNR*100, 4), \"%\\n\")\n","\n","  # Precision\n","  PRECISION = TP/(TP+FP)\n","  print(\"Precision Rate =\",round(PRECISION*100, 4), \"%\")\n","\n","  # Recall\n","  RECALL = TP/(TP+FN)\n","  print(\"Recall Rate =\",round(RECALL*100, 4), \"%\\n\")\n","\n","  # get false and true positive rates\n","  fpr, tpr, thresholds_roc = roc_curve(Y_test, probs_Boost[max_index][:,1], pos_label='spam')\n","  roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr)\n","\n","  # get area under the curve\n","  roc_auc = auc(fpr, tpr)\n","\n","  # get prec and recall rates\n","  prec, recall, thresholds_prc = precision_recall_curve(Y_test, probs_Boost[max_index][:,1], pos_label='spam')\n","  pr_display = PrecisionRecallDisplay(precision=prec, recall=recall)\n","\n","  # get area under the curve\n","  pr_auc = auc(recall, prec)\n","\n","  fig, (ax1, ax2) = plt.subplots(1, 2)\n","  fig.set_size_inches(8, 5)\n","\n","  ax1.plot(fpr, tpr, lw=1)\n","  ax1.plot(FPR, TPR, marker=\"o\", ms = 2, color = 'red')\n","  ax1.set_title('ROC\\nAUC = {}'.format(round(roc_auc,4)))\n","  ax1.set(xlabel = 'False Positive Rate', ylabel = 'True Positive Rate')\n","  ax1.set_xlim([-.1, 1.1])\n","\n","  ax2.plot(recall, prec, lw=1)\n","  ax2.plot(RECALL, PRECISION, marker=\"o\", ms = 2, color = 'red')\n","  ax2.set_title('PR\\nAUC = {}'.format(round(pr_auc,4)))\n","  ax2.set(xlabel = 'Recall', ylabel = 'Precision')\n","  ax2.set_xlim([-.1, 1.1])\n","\n","  plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rW2Od--mmYnM"},"outputs":[],"source":["def Boost_LR_Evaluation():\n","  initialize_Boost()\n","  Boost_LR_predictions()\n","  plot_all_graphs_Boost_LR()\n","  best_accuracy_Boost_LR()\n","\n","def Boost_DTC_Evaluation():\n","  initialize_Boost()\n","  Boost_DTC_predictions()\n","  plot_all_graphs_Boost_DTC()\n","  best_accuracy_Boost_DTC()"]},{"cell_type":"markdown","metadata":{"id":"XKz74cDp4vkh"},"source":["###Results"]},{"cell_type":"code","source":["data_options = \"df_raw\" #@param [\"df_raw\", \"df_normalized\", \"df_standardized\"]\n","split_percentage = 0.7254 #@param {type:\"slider\", min:0, max:1, step:0.0001}\n","rng_seed = 42 #@param {type:\"number\"}\n","rng_seed_split = 42 #@param {type:\"number\"}"],"metadata":{"cellView":"form","id":"fZXgJ6Rd_vWk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UTLveIEVJoPg"},"source":["#### Split Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":128,"status":"ok","timestamp":1651242934446,"user":{"displayName":"Christopher Griffith","userId":"01499139913509777609"},"user_tz":240},"id":"RcrIprMtKWQO","outputId":"8081669e-6122-4bd7-f4ee-49e3dfb87c0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum Features (N) = 57\n","Records = 4601 \n","\n","The data is set to: df_raw\n","\n","Class Distribution - Pre Split\n","ham     60.5955\n","spam    39.4045\n","Name: Class, dtype: float64\n","\n","Class Distribution - Training 0.05%\n","spam    50.0\n","ham     50.0\n","Name: Class, dtype: float64\n","\n","Class Distribution - Testing 99.95%\n","ham     60.6001\n","spam    39.3999\n","Name: Class, dtype: float64\n"]}],"source":["X_features_df = data_selection(data_options)\n","Y_class_labels_df = df['Class']\n","class_labels = Y_class_labels_df.unique()\n","\n","print(\"Maximum Features (N) = {}\".format(len(X_features_df.columns)))\n","print(\"Records = {} \\n\".format(len(X_features_df)))\n","print(\"The data is set to:\", data_options)\n","#print(\"\\n\", X_features_df.describe().round(2))\n","\n","print(\"\\nClass Distribution - Pre Split\")\n","print(round((Y_class_labels_df.value_counts()/Y_class_labels_df.shape)*100,4))\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(X_features_df, Y_class_labels_df, test_size=split_percentage, random_state=rng_seed_split, stratify=Y_class_labels_df) # split data\n","\n","print(\"\\nClass Distribution - Training {}%\".format(round((1-split_percentage)*100, 6)))\n","print(round((Y_train.value_counts() / len(Y_train))*100, 4))\n","\n","print(\"\\nClass Distribution - Testing {}%\".format(round(split_percentage*100,4)))\n","print(round((Y_test.value_counts() / len(Y_test))*100,4))"]},{"cell_type":"markdown","metadata":{"id":"neduE4fWJu33"},"source":["####Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I5Lmwn0kdTXl"},"outputs":[],"source":["# uncomment to review each model\n","#DTC_Evaluation()\n","#RFC_Evaluation()\n","#Boost_LR_Evaluation()\n","#Boost_DTC_Evaluation()"]}],"metadata":{"colab":{"collapsed_sections":["pWyrcftS3Wvj","AV2_Rc9S3Zu7","W7TrkIbA3j7j","_nkc5RG_32VS","iI2KKvAw5HGI","piaUbkYR5N-v","uQ9AEY7m5RR_","zu0tJOuo4BgS","qoAq_pEUH1oT","cM9sNjceIKkS","69LMeEEwISWK","XKz74cDp4vkh","UTLveIEVJoPg","neduE4fWJu33"],"name":"Ensemble_Classifiers_DT_RF_ADA_BOOST.ipynb","provenance":[],"mount_file_id":"1qNLu3fLdS360XM9yJrMqw4s4Th183BKF","authorship_tag":"ABX9TyPEUHaZmpuWHOUuWsh0LRGq"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}